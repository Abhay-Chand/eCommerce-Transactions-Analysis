{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3feec340-c9af-43bc-a37f-1a12d613751a",
   "metadata": {},
   "source": [
    "## Task -01 (ELA AND BUSINESS INSIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0cd14ba4-7c18-44d6-954c-66379a4c9052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers DataFrame:\n",
      "| CustomerID   | CustomerName       | Region        | SignupDate   |\n",
      "|:-------------|:-------------------|:--------------|:-------------|\n",
      "| C0001        | Lawrence Carroll   | South America | 2022-07-10   |\n",
      "| C0002        | Elizabeth Lutz     | Asia          | 2022-02-13   |\n",
      "| C0003        | Michael Rivera     | South America | 2024-03-07   |\n",
      "| C0004        | Kathleen Rodriguez | South America | 2022-10-09   |\n",
      "| C0005        | Laura Weber        | Asia          | 2022-08-15   |\n",
      "\n",
      "Products DataFrame:\n",
      "| ProductID   | ProductName             | Category    | Price   |\n",
      "|:------------|:------------------------|:------------|:--------|\n",
      "| P001        | ActiveWear Biography    | Books       | 169.3   |\n",
      "| P002        | ActiveWear Smartwatch   | Electronics | 346.3   |\n",
      "| P003        | ComfortLiving Biography | Books       | 44.12   |\n",
      "| P004        | BookWorld Rug           | Home Decor  | 95.69   |\n",
      "| P005        | TechPro T-Shirt         | Clothing    | 429.31  |\n",
      "\n",
      "Transactions DataFrame:\n",
      "| TransactionID   | CustomerID   | ProductID   | TransactionDate     | Quantity   | TotalValue   | Price   |\n",
      "|:----------------|:-------------|:------------|:--------------------|:-----------|:-------------|:--------|\n",
      "| T00001          | C0199        | P067        | 2024-08-25 12:38:23 | 1          | 300.68       | 300.68  |\n",
      "| T00112          | C0146        | P067        | 2024-05-27 22:23:54 | 1          | 300.68       | 300.68  |\n",
      "| T00166          | C0127        | P067        | 2024-04-25 7:38:55  | 1          | 300.68       | 300.68  |\n",
      "| T00272          | C0087        | P067        | 2024-03-26 22:55:37 | 2          | 601.36       | 300.68  |\n",
      "| T00363          | C0070        | P067        | 2024-03-21 15:10:10 | 3          | 902.04       | 300.68  |\n",
      "\n",
      "Customers DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   CustomerID    200 non-null    object\n",
      " 1   CustomerName  200 non-null    object\n",
      " 2   Region        200 non-null    object\n",
      " 3   SignupDate    200 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 6.4+ KB\n",
      "None\n",
      "\n",
      "Products DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   ProductID    100 non-null    object \n",
      " 1   ProductName  100 non-null    object \n",
      " 2   Category     100 non-null    object \n",
      " 3   Price        100 non-null    float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 3.3+ KB\n",
      "None\n",
      "\n",
      "Transactions DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   TransactionID    1000 non-null   object \n",
      " 1   CustomerID       1000 non-null   object \n",
      " 2   ProductID        1000 non-null   object \n",
      " 3   TransactionDate  1000 non-null   object \n",
      " 4   Quantity         1000 non-null   int64  \n",
      " 5   TotalValue       1000 non-null   float64\n",
      " 6   Price            1000 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 54.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "customers_df = pd.read_csv(\"Customers.csv\")\n",
    "products_df = pd.read_csv(\"Products.csv\")\n",
    "transactions_df = pd.read_csv(\"Transactions.csv\")\n",
    "\n",
    "# Display the first 5 rows of each DataFrame\n",
    "print(\"Customers DataFrame:\")\n",
    "print(customers_df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "print(\"\\nProducts DataFrame:\")\n",
    "print(products_df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "print(\"\\nTransactions DataFrame:\")\n",
    "print(transactions_df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Display columns and their data types for each DataFrame\n",
    "print(\"\\nCustomers DataFrame Info:\")\n",
    "print(customers_df.info())\n",
    "\n",
    "print(\"\\nProducts DataFrame Info:\")\n",
    "print(products_df.info())\n",
    "\n",
    "print(\"\\nTransactions DataFrame Info:\")\n",
    "print(transactions_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b391c-5891-4385-b437-7c38f1140258",
   "metadata": {},
   "source": [
    "##  Checking the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36fd8a9e-035c-45fd-b67d-deb73947baaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Customers DataFrame:\n",
      "CustomerID      0\n",
      "CustomerName    0\n",
      "Region          0\n",
      "SignupDate      0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Products DataFrame:\n",
      "ProductID      0\n",
      "ProductName    0\n",
      "Category       0\n",
      "Price          0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Transactions DataFrame:\n",
      "TransactionID      0\n",
      "CustomerID         0\n",
      "ProductID          0\n",
      "TransactionDate    0\n",
      "Quantity           0\n",
      "TotalValue         0\n",
      "Price              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each DataFrame\n",
    "print(\"Missing values in Customers DataFrame:\")\n",
    "print(customers_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in Products DataFrame:\")\n",
    "print(products_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in Transactions DataFrame:\")\n",
    "print(transactions_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44649290-c588-47b7-baa5-b72458cac4bb",
   "metadata": {},
   "source": [
    "## TransactionDate column in the transactions_df DataFrame to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5f1ac3e7-d609-490e-960a-eb4cc9ef3239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Transactions DataFrame:\n",
      "| TransactionID   | CustomerID   | ProductID   | TransactionDate     | Quantity   | TotalValue   | Price   |\n",
      "|:----------------|:-------------|:------------|:--------------------|:-----------|:-------------|:--------|\n",
      "| T00001          | C0199        | P067        | 2024-08-25 12:38:23 | 1          | 300.68       | 300.68  |\n",
      "| T00112          | C0146        | P067        | 2024-05-27 22:23:54 | 1          | 300.68       | 300.68  |\n",
      "| T00166          | C0127        | P067        | 2024-04-25 07:38:55 | 1          | 300.68       | 300.68  |\n",
      "| T00272          | C0087        | P067        | 2024-03-26 22:55:37 | 2          | 601.36       | 300.68  |\n",
      "| T00363          | C0070        | P067        | 2024-03-21 15:10:10 | 3          | 902.04       | 300.68  |\n",
      "\n",
      "Updated Transactions DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   TransactionID    1000 non-null   object        \n",
      " 1   CustomerID       1000 non-null   object        \n",
      " 2   ProductID        1000 non-null   object        \n",
      " 3   TransactionDate  1000 non-null   datetime64[ns]\n",
      " 4   Quantity         1000 non-null   int64         \n",
      " 5   TotalValue       1000 non-null   float64       \n",
      " 6   Price            1000 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(3)\n",
      "memory usage: 54.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Convert TransactionDate to datetime\n",
    "transactions_df['TransactionDate'] = pd.to_datetime(transactions_df['TransactionDate'])\n",
    "\n",
    "# Display the first 5 rows of the updated transactions_df\n",
    "print(\"Updated Transactions DataFrame:\")\n",
    "print(transactions_df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Display columns and their data types to check if the conversion was successful\n",
    "print(\"\\nUpdated Transactions DataFrame Info:\")\n",
    "print(transactions_df.info())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2877b5b4-8dab-4c34-a508-8e6a8a0bad78",
   "metadata": {},
   "source": [
    "##  Now, I'll start the actual Exploratory Data Analysis (EDA). I'll begin by analyzing the Customers dataset. First, I'll calculate and display the number of unique values in the CustomerID, CustomerName, and Region columns to understand the customer distribution and identify the regions with the most customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ada0022-5c92-40c1-963f-81408e209f3f",
   "metadata": {},
   "source": [
    "### I'll start by analyzing the Customers dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0c2a66ef-e451-48fe-adf1-5a7b46fd4f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique Customer IDs: 200\n",
      "Number of unique Customer Names: 200\n",
      "Number of unique Regions: 4\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of unique values in CustomerID, CustomerName, and Region\n",
    "unique_customer_ids = customers_df['CustomerID'].nunique()\n",
    "unique_customer_names = customers_df['CustomerName'].nunique()\n",
    "unique_regions = customers_df['Region'].nunique()\n",
    "\n",
    "# Display the results\n",
    "print(\"Number of unique Customer IDs:\", unique_customer_ids)\n",
    "print(\"Number of unique Customer Names:\", unique_customer_names)\n",
    "print(\"Number of unique Regions:\", unique_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "baa1fadc-e855-4712-aa59-1d5e9f676c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now Products Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6d0eef6b-8d37-4b97-ae69-7c5e4eed451c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique Product IDs: 100\n",
      "Number of unique Product Names: 66\n",
      "Number of unique Categories: 4\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of unique values in ProductID, ProductName, and Category\n",
    "unique_product_ids = products_df['ProductID'].nunique()\n",
    "unique_product_names = products_df['ProductName'].nunique()\n",
    "unique_categories = products_df['Category'].nunique()\n",
    "\n",
    "# Display the results\n",
    "print(\"Number of unique Product IDs:\", unique_product_ids)\n",
    "print(\"Number of unique Product Names:\", unique_product_names)\n",
    "print(\"Number of unique Categories:\", unique_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "db39769f-96c7-4c77-8d79-deb39f8de858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most frequently occurring products:\n",
      "\n",
      "| ProductID   | count   |\n",
      "|:------------|:--------|\n",
      "| P059        | 19      |\n",
      "| P029        | 17      |\n",
      "| P062        | 16      |\n",
      "| P079        | 16      |\n",
      "| P054        | 16      |\n",
      "| P061        | 16      |\n",
      "| P048        | 15      |\n",
      "| P022        | 15      |\n",
      "| P096        | 15      |\n",
      "| P049        | 15      |\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the 10 most frequently occurring products\n",
    "top_10_products = transactions_df['ProductID'].value_counts().head(10)\n",
    "print(\"Top 10 most frequently occurring products:\\n\")\n",
    "print(top_10_products.to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1ce22dfc-c039-4149-b338-aa10612888b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most frequently bought product categories:\n",
      "\n",
      "| Category    | count   |\n",
      "|:------------|:--------|\n",
      "| Books       | 270     |\n",
      "| Electronics | 254     |\n",
      "| Home Decor  | 248     |\n",
      "| Clothing    | 228     |\n"
     ]
    }
   ],
   "source": [
    "# Merge products_df and transactions_df on ProductID\n",
    "merged_df = pd.merge(products_df, transactions_df, on='ProductID')\n",
    "\n",
    "# Calculate and display the top 10 product categories\n",
    "top_10_categories = merged_df['Category'].value_counts().head(10)\n",
    "print(\"Top 10 most frequently bought product categories:\\n\")\n",
    "print(top_10_categories.to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ca5d3610-0fe9-4367-8912-21287cb165a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics of Quantity and TotalValue:\n",
      "\n",
      "|       | Quantity   | TotalValue   |\n",
      "|:------|:-----------|:-------------|\n",
      "| count | 1000       | 1000         |\n",
      "| mean  | 2.537      | 689.996      |\n",
      "| std   | 1.11798    | 493.144      |\n",
      "| min   | 1          | 16.08        |\n",
      "| 25%   | 2          | 295.295      |\n",
      "| 50%   | 3          | 588.88       |\n",
      "| 75%   | 4          | 1011.66      |\n",
      "| max   | 4          | 1991.04      |\n"
     ]
    }
   ],
   "source": [
    "# Display descriptive statistics of Quantity and TotalValue\n",
    "print(\"Descriptive statistics of Quantity and TotalValue:\\n\")\n",
    "print(transactions_df[['Quantity', 'TotalValue']].describe().to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85ed1b8-348d-4ff1-b73e-fa63d97dbb8e",
   "metadata": {},
   "source": [
    "### On average, customers purchase 2 to 3 items per transaction, with an average total value of 689.99. The maximum TotalValue is 1991.04, significantly higher than the mean, suggesting potential outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a4ca957e-cd34-4e39-a519-ecbb0631871b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions by Region:\n",
      "| Region        | TransactionCount   |\n",
      "|:--------------|:-------------------|\n",
      "| Asia          | 218                |\n",
      "| Europe        | 234                |\n",
      "| North America | 244                |\n",
      "| South America | 304                |\n"
     ]
    }
   ],
   "source": [
    "# Merge customers_df and transactions_df on CustomerID\n",
    "customer_transactions_df = pd.merge(customers_df, transactions_df, on='CustomerID')\n",
    "\n",
    "# Group by Region and count the number of transactions\n",
    "transactions_by_region = customer_transactions_df.groupby('Region').size().reset_index(name='TransactionCount')\n",
    "\n",
    "# Display the first 5 rows of the grouped DataFrame\n",
    "print(\"Transactions by Region:\")\n",
    "print(transactions_by_region.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "772061f4-d10f-4db9-b2f6-03abe329bf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chand\\anaconda3\\Lib\\site-packages\\altair\\utils\\core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n"
     ]
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "# Create the bar chart\n",
    "chart = alt.Chart(transactions_by_region).mark_bar().encode(\n",
    "    x=alt.X('Region'),\n",
    "    y=alt.Y('TransactionCount'),\n",
    "    tooltip = ['Region', 'TransactionCount']\n",
    ").properties(\n",
    "    title='Distribution of Transactions by Region'\n",
    ").interactive()\n",
    "\n",
    "# Save the chart\n",
    "chart.save('transaction_distribution_by_region_bar_chart.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061fa4e8-1b33-418e-9606-a379009438b5",
   "metadata": {},
   "source": [
    "### >>>South America has the highest number of transactions (304), followed by North America (244)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
